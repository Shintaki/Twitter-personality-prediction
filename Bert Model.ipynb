{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in d:\\users\\shintaki\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: py-params>=0.9.6 in d:\\users\\shintaki\\anaconda3\\lib\\site-packages (from bert-for-tf2) (0.9.7)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in d:\\users\\shintaki\\anaconda3\\lib\\site-packages (from bert-for-tf2) (0.8.0)\n",
      "Requirement already satisfied: tqdm in d:\\users\\shintaki\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.31.1)\n",
      "Requirement already satisfied: numpy in d:\\users\\shintaki\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
      "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
      "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
      "4  ENTJ  'You're fired.|||That's another silly misconce...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/dataset.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(strng, sep, pos):\n",
    "    strng = strng.split(sep)\n",
    "    return sep.join(strng[:pos]), sep.join(strng[pos:])\n",
    "for i,element in enumerate(data.posts):\n",
    "    data.posts[i],_=split(element,\"|||\",15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart = sns.countplot(data.type)\n",
    "plt.title(\"Number of users per personality\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=30, horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    \n",
    "    return [b_Pers[l] for l in personality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to remove these from the posts\n",
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
    "  \n",
    "unique_type_list = unique_type_list + [x.lower() for x in unique_type_list]\n",
    "# Preprocess data\n",
    "def pre_process_data(data, remove_stop_words=True, remove_mbti_profiles=True):\n",
    "\n",
    "    list_personality = []\n",
    "    list_posts = []\n",
    "    len_data = len(data)\n",
    "    i=0\n",
    "    \n",
    "    for row in data.iterrows():\n",
    "        i+=1\n",
    "        if (i % 500 == 0 or i == 1 or i == len_data):\n",
    "            print(\"%s of %s rows\" % (i, len_data))\n",
    "\n",
    "        ##### Remove and clean comments using regular expressions\n",
    "        posts = row[1].posts\n",
    "        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
    "        temp = re.sub('\\|\\|\\|',\"[SEP] \",temp)\n",
    "        temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "        temp = re.sub(' +', ' ', temp)\n",
    "        temp = re.sub(\"(SEP )+\",\"[SEP] \",temp) \n",
    "        if remove_mbti_profiles:\n",
    "            for t in unique_type_list:\n",
    "                temp = temp.replace(t,\"\")\n",
    "        '''temp= \"[CLS]\" + temp\n",
    "        temp = re.sub(\"(\\[CLS\\] *\\[SEP\\])\",\"[CLS] \",temp)'''\n",
    "        temp = re.sub(\"\\[SEP\\]+\",\"| \",temp) \n",
    "        type_labelized = translate_personality(row[1].type)\n",
    "        list_personality.append(type_labelized)\n",
    "        list_posts.append(temp)\n",
    "\n",
    "    list_posts = np.array(list_posts)\n",
    "    list_personality = np.array(list_personality)\n",
    "    return list_posts, list_personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 8675 rows\n",
      "500 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8500 of 8675 rows\n",
      "8675 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "list_posts, list_personality  = pre_process_data(data, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |   and  moments sportscenter not top ten plays pranks |  What has been the most life changing experience in your life |  On repeat for most of today |  May the PerC Experience immerse you |  The last thing my  friend posted on his facebook before committing suicide the next day Rest in peace |  Hello  Sorry to hear of your distress It s only natural for a relationship to not be perfection all the time in every moment of existence Try to figure the hard times as times of growth as |  Welcome and stuff |  Game Set Match |  Prozac wellbrutin at least thirty minutes of moving your legs and I don t mean moving them while sitting in your same desk chair weed in moderation maybe try edibles as a healthier alternative |  Basically come up with three items you ve determined that each type or whichever types you want to do would more than likely use given each types cognitive functions and whatnot when left by |  All things in moderation Sims is indeed a video game and a good one at that Note a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim |  Dear  What were your favorite video games growing up and what are your now current favorite video games cool \n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X=list_posts\n",
    "Y=list_personality\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', \"'\", 'm', 'here', 'to', 'stay', ',', 'hello', 'nice', 'to', 'meet', 'you', 'sir', '[SEP]']\n",
      "[101, 1045, 1005, 1049, 2182, 2000, 2994, 1010, 7592, 3835, 2000, 3113, 2017, 2909, 102]\n"
     ]
    }
   ],
   "source": [
    "# importing the tokenizer and testing it\n",
    "tokenizer = FullTokenizer(\n",
    "  vocab_file=\"./dataset/bert/vocab.txt\"\n",
    ")\n",
    "tokens=tokenizer.tokenize(\"I'm here to stay , hello nice to meet you sir\")\n",
    "tokens=[\"[CLS]\"]+tokens+[\"[SEP]\"]\n",
    "print(tokens)\n",
    "indices=tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 8675 rows\n",
      "1 of 8675 rows\n",
      "500 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8500 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the features\n",
    "def tokenize_features(X):\n",
    "    X_tokenized=[]\n",
    "    for i,entry in enumerate(X):\n",
    "        if (i % 500 == 0 or i == 1 or i == len(X)):\n",
    "            print(\"%s of %s rows\" % (i, len(X)))\n",
    "        temp=[]\n",
    "        temp=tokenizer.tokenize(entry)\n",
    "        temp = [w.replace('|', '[SEP]') for w in temp]\n",
    "        if temp[0] == \"[SEP]\":\n",
    "            temp.pop(0)\n",
    "        temp.insert(0,\"[CLS]\")\n",
    "        temp.append(\"[SEP]\")\n",
    "        X_tokenized.append(temp)\n",
    "    return(X_tokenized)\n",
    "\n",
    "X_tokenized=tokenize_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1998, 5312, 2998, 13013, 2121, 2025, 2327, 2702, 3248, 26418, 2015, 102, 2054, 2038, 2042, 1996, 2087, 2166, 5278, 3325, 1999, 2115, 2166, 102, 2006, 9377, 2005, 2087, 1997, 2651, 102, 2089, 1996, 2566, 2278, 3325, 10047, 16862, 2063, 2017, 102, 1996, 2197, 2518, 2026, 2767, 6866, 2006, 2010, 9130, 2077, 16873, 5920, 1996, 2279, 2154, 2717, 1999, 3521, 102, 7592, 3374, 2000, 2963, 1997, 2115, 12893, 2009, 1055, 2069, 3019, 2005, 1037, 3276, 2000, 2025, 2022, 15401, 2035, 1996, 2051, 1999, 2296, 2617, 1997, 4598, 3046, 2000, 3275, 1996, 2524, 2335, 2004, 2335, 1997, 3930, 2004, 102, 6160, 1998, 4933, 102, 2208, 2275, 2674, 102, 4013, 4143, 2278, 2092, 19892, 21823, 2078, 2012, 2560, 4228, 2781, 1997, 3048, 2115, 3456, 1998, 1045, 2123, 1056, 2812, 3048, 2068, 2096, 3564, 1999, 2115, 2168, 4624, 3242, 17901, 1999, 5549, 8156, 2672, 3046, 21006, 2015, 2004, 1037, 2740, 3771, 4522, 102, 10468, 2272, 2039, 2007, 2093, 5167, 2017, 2310, 4340, 2008, 2169, 2828, 2030, 29221, 4127, 2017, 2215, 2000, 2079, 2052, 2062, 2084, 3497, 2224, 2445, 2169, 4127, 10699, 4972, 1998, 2054, 17048, 2043, 2187, 2011, 102, 2035, 2477, 1999, 5549, 8156, 18135, 2003, 5262, 1037, 2678, 2208, 1998, 1037, 2204, 2028, 2012, 2008, 3602, 1037, 2204, 2028, 2012, 2008, 2003, 5399, 20714, 1999, 2008, 1045, 2572, 2025, 3294, 7694, 1996, 2331, 1997, 2151, 2445, 21934, 102, 6203, 2054, 2020, 2115, 5440, 2678, 2399, 3652, 2039, 1998, 2054, 2024, 2115, 2085, 2783, 5440, 2678, 2399, 4658, 102]\n"
     ]
    }
   ],
   "source": [
    "# indexing the tokens\n",
    "def tokens_to_indices(tokens):\n",
    "    result = []\n",
    "    for element in tokens:\n",
    "        indices =[]\n",
    "        indices=tokenizer.convert_tokens_to_ids(element)\n",
    "        result.append(indices)\n",
    "    return result\n",
    "X_indexed=tokens_to_indices(X_tokenized)\n",
    "print(X_indexed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "435\n"
     ]
    }
   ],
   "source": [
    "# getting the longest indexed array\n",
    "def max_post_words(posts):\n",
    "    maxLen=0\n",
    "    averageLen=0\n",
    "    for post in posts:\n",
    "        averageLen=averageLen+len(post)\n",
    "        if maxLen < len(post):\n",
    "            maxLen=len(post)\n",
    "    averageLen=int(averageLen/len(posts))\n",
    "    return maxLen,averageLen\n",
    "maxLen,avgLen=max_post_words(X_indexed)\n",
    "print(maxLen)\n",
    "print(avgLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding padding \n",
    "def padding(indices):\n",
    "    for i,element in enumerate(indices):\n",
    "        pad=maxLen-len(element)\n",
    "        l = [0] * pad\n",
    "        indices[i]=indices[i] + l\n",
    "    return(indices)\n",
    "X=np.array(padding(X_indexed))\n",
    "Y=(np.array(list_personality[:,0])).astype(np.float32)\n",
    "#Y=(np.array(list_personality)).astype(np.float32)\n",
    "# Not enough memory to train model with maxLen input size so i'll take the first 512\n",
    "#X=X[:,:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():    \n",
    "    with tf.io.gfile.GFile(\"./dataset/bert/bert_config.json\", \"r\") as reader:\n",
    "        bc = StockBertConfig.from_json_string(reader.read())\n",
    "        bert_params = map_stock_config_to_params(bc)\n",
    "        bert_params.adapter_size = None\n",
    "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "    input_ids = keras.layers.Input(shape=(maxLen,), dtype='int16', name=\"input_ids\")\n",
    "    bert_output = bert(input_ids)\n",
    "    print(\"bert shape\", bert_output.shape)\n",
    "    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "    cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "    logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "    logits = keras.layers.Dropout(0.5)(logits)\n",
    "    X1 = keras.layers.Dense(units=1,name=\"I/E_classifier\", activation=\"sigmoid\")(logits)\n",
    "    '''X2 = keras.layers.Dense(units=1,name=\"N/S_classifier\", activation=\"sigmoid\")(logits)\n",
    "    X3 = keras.layers.Dense(units=1,name=\"F/T_classifier\", activation=\"sigmoid\")(logits)\n",
    "    X4 = keras.layers.Dense(units=1,name=\"J/P_classifier\", activation=\"sigmoid\")(logits)\n",
    "    finalOutput=keras.layers.concatenate(\n",
    "    inputs=[X1,X2,X3,X4],\n",
    "    name='final_output')'''\n",
    "    model = keras.Model(inputs=input_ids, outputs=X1)\n",
    "    model.build(input_shape=(None, maxLen))\n",
    "    load_stock_weights(bert, \"./dataset/bert/bert_model.ckpt\")\n",
    "    model.layers[1].trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert shape (None, 643, 768)\n",
      "loader: Skipping weight:[bert/embeddings/position_embeddings/embeddings:0] as the weight shape:[(1083, 768)] is not compatible with the checkpoint:[bert/embeddings/position_embeddings] shape:(512, 768)\n",
      "Done loading 195 BERT weights from: ./dataset/bert/bert_model.ckpt into <bert.model.BertModelLayer object at 0x00000197F3BAC668> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [1]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/position_embeddings\n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 643)]             0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 643, 768)          109328640 \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "I/E_classifier (Dense)       (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 109,920,001\n",
      "Trainable params: 591,361\n",
      "Non-trainable params: 109,328,640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bertModel = create_model()\n",
    "bertModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_loss(y_true,y_pred):\n",
    "    return K.mean(K.sum(K.binary_crossentropy(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 643)\n",
      "(8675,)\n",
      "Train on 6940 samples, validate on 867 samples\n",
      "1504/6940 [=====>........................] - ETA: 58:39 - loss: 0.7721 - accuracy: 0.5938 - f1: 0.43 - ETA: 39:17 - loss: 0.7578 - accuracy: 0.5781 - f1: 0.36 - ETA: 32:45 - loss: 0.7513 - accuracy: 0.5833 - f1: 0.32 - ETA: 29:27 - loss: 0.7558 - accuracy: 0.5625 - f1: 0.31 - ETA: 27:27 - loss: 0.7695 - accuracy: 0.5375 - f1: 0.33 - ETA: 26:04 - loss: 0.7790 - accuracy: 0.5104 - f1: 0.30 - ETA: 25:04 - loss: 0.7875 - accuracy: 0.5000 - f1: 0.29 - ETA: 24:17 - loss: 0.7868 - accuracy: 0.5078 - f1: 0.31 - ETA: 23:40 - loss: 0.7724 - accuracy: 0.5139 - f1: 0.31 - ETA: 23:09 - loss: 0.7675 - accuracy: 0.5188 - f1: 0.29 - ETA: 22:43 - loss: 0.7521 - accuracy: 0.5398 - f1: 0.28 - ETA: 22:21 - loss: 0.7479 - accuracy: 0.5391 - f1: 0.29 - ETA: 22:00 - loss: 0.7558 - accuracy: 0.5288 - f1: 0.28 - ETA: 21:42 - loss: 0.7530 - accuracy: 0.5335 - f1: 0.28 - ETA: 21:26 - loss: 0.7450 - accuracy: 0.5417 - f1: 0.28 - ETA: 21:11 - loss: 0.7405 - accuracy: 0.5430 - f1: 0.27 - ETA: 20:57 - loss: 0.7273 - accuracy: 0.5533 - f1: 0.25 - ETA: 20:44 - loss: 0.7273 - accuracy: 0.5556 - f1: 0.25 - ETA: 20:32 - loss: 0.7216 - accuracy: 0.5609 - f1: 0.25 - ETA: 20:20 - loss: 0.7142 - accuracy: 0.5688 - f1: 0.26 - ETA: 20:09 - loss: 0.7144 - accuracy: 0.5699 - f1: 0.26 - ETA: 19:58 - loss: 0.7045 - accuracy: 0.5795 - f1: 0.26 - ETA: 19:48 - loss: 0.6944 - accuracy: 0.5897 - f1: 0.26 - ETA: 19:38 - loss: 0.6882 - accuracy: 0.5951 - f1: 0.26 - ETA: 19:29 - loss: 0.6842 - accuracy: 0.5987 - f1: 0.25 - ETA: 19:20 - loss: 0.6846 - accuracy: 0.5986 - f1: 0.25 - ETA: 19:11 - loss: 0.6847 - accuracy: 0.6019 - f1: 0.24 - ETA: 19:02 - loss: 0.6846 - accuracy: 0.6004 - f1: 0.24 - ETA: 18:54 - loss: 0.6838 - accuracy: 0.6024 - f1: 0.23 - ETA: 18:45 - loss: 0.6804 - accuracy: 0.6052 - f1: 0.23 - ETA: 18:37 - loss: 0.6858 - accuracy: 0.6038 - f1: 0.22 - ETA: 18:30 - loss: 0.6856 - accuracy: 0.6055 - f1: 0.22 - ETA: 18:22 - loss: 0.6860 - accuracy: 0.6070 - f1: 0.21 - ETA: 18:14 - loss: 0.6837 - accuracy: 0.6085 - f1: 0.21 - ETA: 18:06 - loss: 0.6840 - accuracy: 0.6107 - f1: 0.21 - ETA: 17:59 - loss: 0.6808 - accuracy: 0.6155 - f1: 0.21 - ETA: 17:52 - loss: 0.6798 - accuracy: 0.6191 - f1: 0.21 - ETA: 17:44 - loss: 0.6766 - accuracy: 0.6234 - f1: 0.21 - ETA: 17:37 - loss: 0.6751 - accuracy: 0.6242 - f1: 0.21 - ETA: 17:30 - loss: 0.6733 - accuracy: 0.6258 - f1: 0.21 - ETA: 17:23 - loss: 0.6703 - accuracy: 0.6288 - f1: 0.21 - ETA: 17:16 - loss: 0.6648 - accuracy: 0.6324 - f1: 0.21 - ETA: 17:09 - loss: 0.6633 - accuracy: 0.6344 - f1: 0.21 - ETA: 17:02 - loss: 0.6599 - accuracy: 0.6385 - f1: 0.21 - ETA: 16:55 - loss: 0.6583 - accuracy: 0.6403 - f1: 0.20 - ETA: 16:49 - loss: 0.6561 - accuracy: 0.6413 - f1: 0.20 - ETA: 16:42 - loss: 0.6530 - accuracy: 0.6436 - f1: 0.1976"
     ]
    }
   ],
   "source": [
    "# Defining hyperparameters\n",
    "EPOCHS = 1\n",
    "BS = 32\n",
    "LR=1e-5\n",
    "# Compiling and training\n",
    "bertModel.compile(\n",
    "  optimizer=keras.optimizers.Adam(LR),\n",
    "  loss=\"binary_crossentropy\",\n",
    "  metrics=[\"accuracy\",f1]\n",
    ")\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "(X_train, X_temp, Y_train, Y_temp) = train_test_split(X,Y,test_size=0.2, random_state=42)\n",
    "(X_valid, X_test, Y_valid, Y_test) = train_test_split(X_temp,Y_temp,test_size=0.5, random_state=42)\n",
    "history = bertModel.fit(\n",
    "  X_train, \n",
    "  Y_train,\n",
    "  validation_data=(X_valid,Y_valid),\n",
    "  batch_size=BS,\n",
    "  shuffle=True,\n",
    "  epochs=EPOCHS,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868/868 [==============================] - ETA: 2:06 - loss: 0.6506 - accuracy: 0.6875 - f1: 0.0000e+0 - ETA: 2:01 - loss: 0.5433 - accuracy: 0.7656 - f1: 0.0000e+0 - ETA: 1:55 - loss: 0.5227 - accuracy: 0.7812 - f1: 0.0000e+0 - ETA: 1:51 - loss: 0.5448 - accuracy: 0.7656 - f1: 0.0000e+0 - ETA: 1:46 - loss: 0.5512 - accuracy: 0.7625 - f1: 0.0000e+0 - ETA: 1:41 - loss: 0.5468 - accuracy: 0.7656 - f1: 0.0000e+0 - ETA: 1:36 - loss: 0.5374 - accuracy: 0.7723 - f1: 0.0000e+0 - ETA: 1:31 - loss: 0.5465 - accuracy: 0.7656 - f1: 0.0000e+0 - ETA: 1:26 - loss: 0.5393 - accuracy: 0.7708 - f1: 0.0000e+0 - ETA: 1:22 - loss: 0.5341 - accuracy: 0.7750 - f1: 0.0000e+0 - ETA: 1:17 - loss: 0.5338 - accuracy: 0.7756 - f1: 0.0000e+0 - ETA: 1:12 - loss: 0.5374 - accuracy: 0.7734 - f1: 0.0000e+0 - ETA: 1:07 - loss: 0.5488 - accuracy: 0.7644 - f1: 0.0000e+0 - ETA: 1:03 - loss: 0.5387 - accuracy: 0.7723 - f1: 0.0000e+0 - ETA: 58s - loss: 0.5483 - accuracy: 0.7646 - f1: 0.0000e+0 - ETA: 53s - loss: 0.5490 - accuracy: 0.7637 - f1: 0.0000e+ - ETA: 48s - loss: 0.5428 - accuracy: 0.7684 - f1: 0.0000e+ - ETA: 44s - loss: 0.5533 - accuracy: 0.7604 - f1: 0.0000e+ - ETA: 39s - loss: 0.5582 - accuracy: 0.7566 - f1: 0.0000e+ - ETA: 34s - loss: 0.5590 - accuracy: 0.7563 - f1: 0.0000e+ - ETA: 29s - loss: 0.5598 - accuracy: 0.7560 - f1: 0.0000e+ - ETA: 24s - loss: 0.5543 - accuracy: 0.7599 - f1: 0.0000e+ - ETA: 20s - loss: 0.5566 - accuracy: 0.7582 - f1: 0.0000e+ - ETA: 15s - loss: 0.5531 - accuracy: 0.7604 - f1: 0.0000e+ - ETA: 10s - loss: 0.5474 - accuracy: 0.7650 - f1: 0.0000e+ - ETA: 5s - loss: 0.5450 - accuracy: 0.7668 - f1: 0.0000e+00 - ETA: 0s - loss: 0.5429 - accuracy: 0.7685 - f1: 0.0000e+0 - 132s 153ms/sample - loss: 0.5445 - accuracy: 0.7673 - f1: 0.0000e+00\n",
      "Accuracy :  0.7672811\n",
      "F1 Score : 0.0\n",
      "Loss : 0.5444843219721922\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc,test_f1 = bertModel.evaluate(X_test,Y_test)\n",
    "print(\"Accuracy : \",test_acc)\n",
    "print(\"F1 Score :\",test_f1)\n",
    "print(\"Loss :\",test_loss)\n",
    "Yhat=bertModel.predict(X_test)\n",
    "correct=0\n",
    "correctlabels=[0,0,0,0]\n",
    "for i,prediction in enumerate(Yhat):\n",
    "    for j,value in enumerate(prediction):\n",
    "        if (value<0.5):\n",
    "            prediction[j]=0\n",
    "        else:\n",
    "            prediction[j]=1\n",
    "        if(prediction[j]==Y_test[i][j]):\n",
    "            correctlabels[j]+=1\n",
    "    if (np.array_equal(prediction,Y_test[i])):\n",
    "        correct+=1\n",
    "    print(\"Prediction :\",prediction,\" Actual Value :\",Y_test[i] )\n",
    "print(\"Total accuracy : \",correct/len(X_test))\n",
    "print(\"I/E accuracy : \",correctlabels[0]/len(X_test))\n",
    "print(\"N/S accuracy : \",correctlabels[1]/len(X_test))\n",
    "print(\"F/T accuracy : \",correctlabels[2]/len(X_test))\n",
    "print(\"J/P accuracy : \",correctlabels[3]/len(X_test))\n",
    "print(\"Binary accuracy :\",np.sum(correctlabels)/(4*len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
