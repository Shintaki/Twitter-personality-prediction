{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/84/1bea6c34d38f3e726830d3adeca76e6e901b98cf5babd635883dbedd7ecc/bert-for-tf2-0.14.1.tar.gz (40kB)\n",
      "Collecting py-params>=0.9.6 (from bert-for-tf2)\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
      "Collecting params-flow>=0.8.0 (from bert-for-tf2)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/0d/615c0d4aea541b4f47c761263809a02e160e7a2babd175f0ddd804776cf4/params-flow-0.8.0.tar.gz\n",
      "Requirement already satisfied: numpy in d:\\users\\shintaki\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.1)\n",
      "Requirement already satisfied: tqdm in d:\\users\\shintaki\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.31.1)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py): started\n",
      "  Building wheel for bert-for-tf2 (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Shintaki\\AppData\\Local\\pip\\Cache\\wheels\\dd\\f1\\10\\861fd7899727e4034293fb1dfef45b00f8cd476d21d3b3821e\n",
      "  Building wheel for py-params (setup.py): started\n",
      "  Building wheel for py-params (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Shintaki\\AppData\\Local\\pip\\Cache\\wheels\\67\\f5\\19\\b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
      "  Building wheel for params-flow (setup.py): started\n",
      "  Building wheel for params-flow (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Shintaki\\AppData\\Local\\pip\\Cache\\wheels\\88\\41\\05\\1a9955d1d01575bbd58aab76e22f8c7eeabba905d551576f43\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.1 params-flow-0.8.0 py-params-0.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
      "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
      "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
      "4  ENTJ  'You're fired.|||That's another silly misconce...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/dataset.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart = sns.countplot(data.type)\n",
    "plt.title(\"Number of users per personality\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=30, horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    \n",
    "    return [b_Pers[l] for l in personality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to remove these from the posts\n",
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
    "  \n",
    "unique_type_list = unique_type_list + [x.lower() for x in unique_type_list]\n",
    "# Preprocess data\n",
    "def pre_process_data(data, remove_stop_words=True, remove_mbti_profiles=True):\n",
    "\n",
    "    list_personality = []\n",
    "    list_posts = []\n",
    "    len_data = len(data)\n",
    "    i=0\n",
    "    \n",
    "    for row in data.iterrows():\n",
    "        i+=1\n",
    "        if (i % 500 == 0 or i == 1 or i == len_data):\n",
    "            print(\"%s of %s rows\" % (i, len_data))\n",
    "\n",
    "        ##### Remove and clean comments using regular expressions\n",
    "        posts = row[1].posts\n",
    "        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
    "        temp = re.sub('\\|\\|\\|',\"[SEP] \",temp)\n",
    "        temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "        temp = re.sub(' +', ' ', temp)\n",
    "        temp = re.sub(\"(SEP )+\",\"[SEP] \",temp) \n",
    "        if remove_mbti_profiles:\n",
    "            for t in unique_type_list:\n",
    "                temp = temp.replace(t,\"\")\n",
    "        '''temp= \"[CLS]\" + temp\n",
    "        temp = re.sub(\"(\\[CLS\\] *\\[SEP\\])\",\"[CLS] \",temp)'''\n",
    "        temp = re.sub(\"\\[SEP\\]+\",\"| \",temp) \n",
    "        type_labelized = translate_personality(row[1].type)\n",
    "        list_personality.append(type_labelized)\n",
    "        list_posts.append(temp)\n",
    "\n",
    "    list_posts = np.array(list_posts)\n",
    "    list_personality = np.array(list_personality)\n",
    "    return list_posts, list_personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 8675 rows\n",
      "500 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8500 of 8675 rows\n",
      "8675 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "list_posts, list_personality  = pre_process_data(data, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |   and  moments sportscenter not top ten plays pranks |  What has been the most life changing experience in your life |  On repeat for most of today |  May the PerC Experience immerse you |  The last thing my  friend posted on his facebook before committing suicide the next day Rest in peace |  Hello  Sorry to hear of your distress It s only natural for a relationship to not be perfection all the time in every moment of existence Try to figure the hard times as times of growth as |  Welcome and stuff |  Game Set Match |  Prozac wellbrutin at least thirty minutes of moving your legs and I don t mean moving them while sitting in your same desk chair weed in moderation maybe try edibles as a healthier alternative |  Basically come up with three items you ve determined that each type or whichever types you want to do would more than likely use given each types cognitive functions and whatnot when left by |  All things in moderation Sims is indeed a video game and a good one at that Note a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim |  Dear  What were your favorite video games growing up and what are your now current favorite video games cool |  It appears to be too late sad |  There s someone out there for everyone |  Wait I thought confidence was a good thing |  I just cherish the time of solitude b c i revel within my inner world more whereas most other time i d be workin just enjoy the me time while you can Don t worry people will always be around to |  Yo  ladies if you re into a complimentary personality well hey |  when your main social outlet is xbox live conversations and even then you verbally fatigue quickly |  I really dig the part from to |  Banned because this thread requires it of me |  Get high in backyard roast and eat marshmellows in backyard while conversing over something intellectual followed by massages and kisses |  Banned for too many b s in that sentence How could you Think of the B |  Banned for watching movies in the corner with the dunces |  Banned because Health class clearly taught you nothing about peer pressure |  Banned for a whole host of reasons |  Two baby deer on left and right munching on a beetle in the middle Using their own blood two cavemen diary today s latest happenings on their designated cave diary wall I see it as |  a pokemon world an  society everyone becomes an optimist |  Not all artists are artists because they draw It s the idea that counts in forming something of your own like a signature |  Welcome to the robot ranks person who downed my self esteem cuz I m not an avid signature artist like herself proud |  Banned for taking all the room under my bed Ya gotta learn to share with the roaches |  Banned for being too much of a thundering grumbling kind of storm yep |  Ahh old high school music I haven t heard in ages |  I failed a public speaking class a few years ago and I ve sort of learned what I could do better were I to be in that position again A big part of my failure was just overloading myself with too |  I like this person s mentality He s a confirmed  by the way |  Move to the Denver area and start a new life for myself \n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X=list_posts\n",
    "Y=list_personality\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', \"'\", 'm', 'here', 'to', 'stay', ',', 'hello', 'nice', 'to', 'meet', 'you', 'sir', '[SEP]']\n",
      "[101, 1045, 1005, 1049, 2182, 2000, 2994, 1010, 7592, 3835, 2000, 3113, 2017, 2909, 102]\n"
     ]
    }
   ],
   "source": [
    "# importing the tokenizer and testing it\n",
    "tokenizer = FullTokenizer(\n",
    "  vocab_file=\"./dataset/bert/vocab.txt\"\n",
    ")\n",
    "tokens=tokenizer.tokenize(\"I'm here to stay , hello nice to meet you sir\")\n",
    "tokens=[\"[CLS]\"]+tokens+[\"[SEP]\"]\n",
    "print(tokens)\n",
    "indices=tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 8675 rows\n",
      "1 of 8675 rows\n",
      "500 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8500 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the features\n",
    "def tokenize_features(X):\n",
    "    X_tokenized=[]\n",
    "    for i,entry in enumerate(X):\n",
    "        if (i % 500 == 0 or i == 1 or i == len(X)):\n",
    "            print(\"%s of %s rows\" % (i, len(X)))\n",
    "        temp=[]\n",
    "        temp=tokenizer.tokenize(entry)\n",
    "        temp = [w.replace('|', '[SEP]') for w in temp]\n",
    "        if temp[0] == \"[SEP]\":\n",
    "            temp.pop(0)\n",
    "        temp.insert(0,\"[CLS]\")\n",
    "        temp.append(\"[SEP]\")\n",
    "        X_tokenized.append(temp)\n",
    "    return(X_tokenized)\n",
    "\n",
    "X_tokenized=tokenize_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1998, 5312, 2998, 13013, 2121, 2025, 2327, 2702, 3248, 26418, 2015, 102, 2054, 2038, 2042, 1996, 2087, 2166, 5278, 3325, 1999, 2115, 2166, 102, 2006, 9377, 2005, 2087, 1997, 2651, 102, 2089, 1996, 2566, 2278, 3325, 10047, 16862, 2063, 2017, 102, 1996, 2197, 2518, 2026, 2767, 6866, 2006, 2010, 9130, 2077, 16873, 5920, 1996, 2279, 2154, 2717, 1999, 3521, 102, 7592, 3374, 2000, 2963, 1997, 2115, 12893, 2009, 1055, 2069, 3019, 2005, 1037, 3276, 2000, 2025, 2022, 15401, 2035, 1996, 2051, 1999, 2296, 2617, 1997, 4598, 3046, 2000, 3275, 1996, 2524, 2335, 2004, 2335, 1997, 3930, 2004, 102, 6160, 1998, 4933, 102, 2208, 2275, 2674, 102, 4013, 4143, 2278, 2092, 19892, 21823, 2078, 2012, 2560, 4228, 2781, 1997, 3048, 2115, 3456, 1998, 1045, 2123, 1056, 2812, 3048, 2068, 2096, 3564, 1999, 2115, 2168, 4624, 3242, 17901, 1999, 5549, 8156, 2672, 3046, 21006, 2015, 2004, 1037, 2740, 3771, 4522, 102, 10468, 2272, 2039, 2007, 2093, 5167, 2017, 2310, 4340, 2008, 2169, 2828, 2030, 29221, 4127, 2017, 2215, 2000, 2079, 2052, 2062, 2084, 3497, 2224, 2445, 2169, 4127, 10699, 4972, 1998, 2054, 17048, 2043, 2187, 2011, 102, 2035, 2477, 1999, 5549, 8156, 18135, 2003, 5262, 1037, 2678, 2208, 1998, 1037, 2204, 2028, 2012, 2008, 3602, 1037, 2204, 2028, 2012, 2008, 2003, 5399, 20714, 1999, 2008, 1045, 2572, 2025, 3294, 7694, 1996, 2331, 1997, 2151, 2445, 21934, 102, 6203, 2054, 2020, 2115, 5440, 2678, 2399, 3652, 2039, 1998, 2054, 2024, 2115, 2085, 2783, 5440, 2678, 2399, 4658, 102, 2009, 3544, 2000, 2022, 2205, 2397, 6517, 102, 2045, 1055, 2619, 2041, 2045, 2005, 3071, 102, 3524, 1045, 2245, 7023, 2001, 1037, 2204, 2518, 102, 1045, 2074, 24188, 4509, 1996, 2051, 1997, 22560, 1038, 1039, 1045, 7065, 2884, 2306, 2026, 5110, 2088, 2062, 6168, 2087, 2060, 2051, 1045, 1040, 2022, 2147, 2378, 2074, 5959, 1996, 2033, 2051, 2096, 2017, 2064, 2123, 1056, 4737, 2111, 2097, 2467, 2022, 2105, 2000, 102, 10930, 6456, 2065, 2017, 2128, 2046, 1037, 19394, 5649, 6180, 2092, 4931, 102, 2043, 2115, 2364, 2591, 13307, 2003, 12202, 2444, 11450, 1998, 2130, 2059, 2017, 12064, 2135, 16342, 2855, 102, 1045, 2428, 10667, 1996, 2112, 2013, 2000, 102, 7917, 2138, 2023, 11689, 5942, 2009, 1997, 2033, 102, 2131, 2152, 1999, 16125, 25043, 1998, 4521, 9409, 10199, 8261, 2015, 1999, 16125, 2096, 9530, 14028, 2075, 2058, 2242, 7789, 2628, 2011, 21881, 2015, 1998, 8537, 102, 7917, 2005, 2205, 2116, 1038, 1055, 1999, 2008, 6251, 2129, 2071, 2017, 2228, 1997, 1996, 1038, 102, 7917, 2005, 3666, 5691, 1999, 1996, 3420, 2007, 1996, 24654, 9623, 102, 7917, 2138, 2740, 2465, 4415, 4036, 2017, 2498, 2055, 8152, 3778, 102, 7917, 2005, 1037, 2878, 3677, 1997, 4436, 102, 2048, 3336, 8448, 2006, 2187, 1998, 2157, 14163, 12680, 2075, 2006, 1037, 7813, 1999, 1996, 2690, 2478, 2037, 2219, 2668, 2048, 5430, 3549, 9708, 2651, 1055, 6745, 6230, 2015, 2006, 2037, 4351, 5430, 9708, 2813, 1045, 2156, 2009, 2004, 102, 1037, 20421, 2088, 2019, 2554, 3071, 4150, 2019, 23569, 27605, 3367, 102, 2025, 2035, 3324, 2024, 3324, 2138, 2027, 4009, 2009, 1055, 1996, 2801, 2008, 9294, 1999, 5716, 2242, 1997, 2115, 2219, 2066, 1037, 8085, 102, 6160, 2000, 1996, 8957, 6938, 2711, 2040, 20164, 2026, 2969, 19593, 12731, 2480, 1045, 1049, 2025, 2019, 18568, 8085, 3063, 2066, 2841, 7098, 102, 7917, 2005, 2635, 2035, 1996, 2282, 2104, 2026, 2793, 8038, 10657, 4553, 2000, 3745, 2007, 1996, 20997, 2229, 102, 7917, 2005, 2108, 2205, 2172, 1997, 1037, 8505, 2075, 24665, 25438, 2989, 2785, 1997, 4040, 15624, 102, 6289, 2232, 2214, 2152, 2082, 2189, 1045, 4033, 1056, 2657, 1999, 5535, 102, 1045, 3478, 1037, 2270, 4092, 2465, 1037, 2261, 2086, 3283, 1998, 1045, 2310, 4066, 1997, 4342, 2054, 1045, 2071, 2079, 2488, 2020, 1045, 2000, 2022, 1999, 2008, 2597, 2153, 1037, 2502, 2112, 1997, 2026, 4945, 2001, 2074, 2058, 18570, 2870, 2007, 2205, 102, 1045, 2066, 2023, 2711, 1055, 5177, 3012, 2002, 1055, 1037, 4484, 2011, 1996, 2126, 102, 2693, 2000, 1996, 7573, 2181, 1998, 2707, 1037, 2047, 2166, 2005, 2870, 102]\n"
     ]
    }
   ],
   "source": [
    "# indexing the tokens\n",
    "def tokens_to_indices(tokens):\n",
    "    result = []\n",
    "    for element in tokens:\n",
    "        indices =[]\n",
    "        indices=tokenizer.convert_tokens_to_ids(element)\n",
    "        result.append(indices)\n",
    "    return result\n",
    "X_indexed=tokens_to_indices(X_tokenized)\n",
    "print(X_indexed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132\n",
      "1418\n"
     ]
    }
   ],
   "source": [
    "# getting the longest indexed array\n",
    "def max_post_words(posts):\n",
    "    maxLen=0\n",
    "    averageLen=0\n",
    "    for post in posts:\n",
    "        averageLen=averageLen+len(post)\n",
    "        if maxLen < len(post):\n",
    "            maxLen=len(post)\n",
    "    averageLen=int(averageLen/len(posts))\n",
    "    return maxLen,averageLen\n",
    "maxLen,avgLen=max_post_words(X_indexed)\n",
    "print(maxLen)\n",
    "print(avgLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding padding \n",
    "def padding(indices):\n",
    "    for i,element in enumerate(indices):\n",
    "        pad=maxLen-len(element)\n",
    "        l = [0] * pad\n",
    "        indices[i]=indices[i] + l\n",
    "    return(indices)\n",
    "X=np.array(padding(X_indexed))\n",
    "Y=(np.array(list_personality[:,0])).astype(np.float32)\n",
    "#Y=(np.array(list_personality)).astype(np.float32)\n",
    "# Not enough memory to train model with maxLen input size so i'll take the first 512\n",
    "#X=X[:,:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():    \n",
    "    with tf.io.gfile.GFile(\"./dataset/bert/bert_config.json\", \"r\") as reader:\n",
    "        bc = StockBertConfig.from_json_string(reader.read())\n",
    "        bert_params = map_stock_config_to_params(bc)\n",
    "        bert_params.adapter_size = None\n",
    "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "    input_ids = keras.layers.Input(shape=(maxLen,), dtype='int16', name=\"input_ids\")\n",
    "    bert_output = bert(input_ids)\n",
    "    print(\"bert shape\", bert_output.shape)\n",
    "    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "    cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "    logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "    logits = keras.layers.Dropout(0.5)(logits)\n",
    "    X1 = keras.layers.Dense(units=1,name=\"I/E_classifier\", activation=\"sigmoid\")(logits)\n",
    "    '''X2 = keras.layers.Dense(units=1,name=\"N/S_classifier\", activation=\"sigmoid\")(logits)\n",
    "    X3 = keras.layers.Dense(units=1,name=\"F/T_classifier\", activation=\"sigmoid\")(logits)\n",
    "    X4 = keras.layers.Dense(units=1,name=\"J/P_classifier\", activation=\"sigmoid\")(logits)\n",
    "    finalOutput=keras.layers.concatenate(\n",
    "    inputs=[X1,X2,X3,X4],\n",
    "    name='final_output')'''\n",
    "    model = keras.Model(inputs=input_ids, outputs=X1)\n",
    "    model.build(input_shape=(None, maxLen))\n",
    "    load_stock_weights(bert, \"./dataset/bert/bert_model.ckpt\")\n",
    "    model.layers[1].trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert shape (None, 2132, 768)\n",
      "loader: Skipping weight:[bert/embeddings/position_embeddings/embeddings:0] as the weight shape:[(2132, 768)] is not compatible with the checkpoint:[bert/embeddings/position_embeddings] shape:(512, 768)\n",
      "Done loading 195 BERT weights from: ./dataset/bert/bert_model.ckpt into <bert.model.BertModelLayer object at 0x0000013F1FA48748> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [1]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/position_embeddings\n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 2132)]            0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 2132, 768)         110134272 \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "I/E_classifier (Dense)       (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 110,725,633\n",
      "Trainable params: 591,361\n",
      "Non-trainable params: 110,134,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bertModel = create_model()\n",
    "bertModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_loss(y_true,y_pred):\n",
    "    return K.mean(K.sum(K.binary_crossentropy(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 2132)\n",
      "(8675,)\n",
      "Train on 6940 samples, validate on 867 samples\n",
      "Epoch 1/5\n",
      "  32/6940 [..............................] - ETA: 1:25:00"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,12,2132,2132] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/bert/encoder/layer_0/attention/self/MatMul (defined at D:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\bert\\attention.py:112) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_27301]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/bert/encoder/layer_0/attention/self/MatMul:\n model/bert/encoder/layer_0/attention/self/transpose (defined at D:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\bert\\attention.py:103)\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-dfe662dd6a31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m   \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m )\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mD:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,12,2132,2132] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/bert/encoder/layer_0/attention/self/MatMul (defined at D:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\bert\\attention.py:112) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_27301]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/bert/encoder/layer_0/attention/self/MatMul:\n model/bert/encoder/layer_0/attention/self/transpose (defined at D:\\Users\\Shintaki\\Anaconda3\\lib\\site-packages\\bert\\attention.py:103)\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "# Defining hyperparameters\n",
    "EPOCHS = 5\n",
    "BS = 32\n",
    "LR=1e-5\n",
    "# Compiling and training\n",
    "bertModel.compile(\n",
    "  optimizer=keras.optimizers.Adam(LR),\n",
    "  loss=\"binary_crossentropy\",\n",
    "  metrics=[\"accuracy\",f1]\n",
    ")\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "(X_train, X_temp, Y_train, Y_temp) = train_test_split(X,Y,test_size=0.2, random_state=42)\n",
    "(X_valid, X_test, Y_valid, Y_test) = train_test_split(X_temp,Y_temp,test_size=0.5, random_state=42)\n",
    "history = bertModel.fit(\n",
    "  X_train, \n",
    "  Y_train,\n",
    "  validation_data=(X_valid,Y_valid),\n",
    "  batch_size=BS,\n",
    "  shuffle=True,\n",
    "  epochs=EPOCHS,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc,test_f1 = bertModel.evaluate(X_test,Y_test)\n",
    "print(\"Accuracy : \",test_acc)\n",
    "print(\"F1 Score :\",test_f1)\n",
    "print(\"Loss :\",test_loss)\n",
    "Yhat=bertModel.predict(X_test)\n",
    "correct=0\n",
    "correctlabels=[0,0,0,0]\n",
    "for i,prediction in enumerate(Yhat):\n",
    "    for j,value in enumerate(prediction):\n",
    "        if (value<0.5):\n",
    "            prediction[j]=0\n",
    "        else:\n",
    "            prediction[j]=1\n",
    "        if(prediction[j]==Y_test[i][j]):\n",
    "            correctlabels[j]+=1\n",
    "    if (np.array_equal(prediction,Y_test[i])):\n",
    "        correct+=1\n",
    "    print(\"Prediction :\",prediction,\" Actual Value :\",Y_test[i] )\n",
    "print(\"Total accuracy : \",correct/len(X_test))\n",
    "print(\"I/E accuracy : \",correctlabels[0]/len(X_test))\n",
    "print(\"N/S accuracy : \",correctlabels[1]/len(X_test))\n",
    "print(\"F/T accuracy : \",correctlabels[2]/len(X_test))\n",
    "print(\"J/P accuracy : \",correctlabels[3]/len(X_test))\n",
    "print(\"Binary accuracy :\",np.sum(correctlabels)/(4*len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
